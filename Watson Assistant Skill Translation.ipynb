{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson Assistant Translation Notebook \n",
    "by: Pratyush Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson Assistant Skill Translation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running this cell once, comment out the following code. Packages only need to be installed once.\n",
    "!pip install --user --upgrade -q \"ibm-watson\";\n",
    "!pip install --user --upgrade -q \"bokeh==2.0.0\";\n",
    "!pip install --user --upgrade -q \"pandas==1.0.1\";\n",
    "!pip install --user --upgrade -q \"tqdm==4.43.0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "from IPython.display import display\n",
    "from ibm_cloud_sdk_core.authenticators import BasicAuthenticator\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson import LanguageTranslatorV3\n",
    "from ibm_watson import AssistantV1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = BasicAuthenticator('apikey', '<API_KEY_WATSON_ASSISTANT>')\n",
    "sdk_object = AssistantV1(version='2020-02-05', authenticator=authenticator)\n",
    "sdk_object.set_service_url('<SERVICE_URL>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_information = {'workspace_id' : '<WORKSPACE_ID>',\n",
    "                         'assistant_id' : '<ASSISTANT_ID>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_authenticator = IAMAuthenticator('<LANGUAGE_TRANSLATOR_API_KEY')\n",
    "language_translator = LanguageTranslatorV3(version='2020-04-01', authenticator=lt_authenticator)\n",
    "\n",
    "language_translator.set_service_url('<LANGUAGE_TRANSLATOR_URL>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text:str) -> str:\n",
    "    \"\"\" Translates the text into Spanish\n",
    "    \n",
    "    Calls the Watson Language Translator Service to translate the input text.\n",
    "    \n",
    "    Args: \n",
    "    - text: the input text\n",
    "    \n",
    "    Returns:\n",
    "    - translate: the translated output\n",
    "    \"\"\"\n",
    "    if not len(text):\n",
    "        return text\n",
    "    \n",
    "    result = language_translator.translate(text=text, model_id='en-es').get_result()\n",
    "    translate = result['translations'][0]['translation']\n",
    "    \n",
    "    return translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Intents and Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sdk_object.list_intents(workspace_id=assistant_information['workspace_id']).get_result() #handle pagination\n",
    "intents = [intent['intent'] for intent in response['intents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_intent_examples(intent:str) -> str:\n",
    "    \"\"\" Retrieves the intent examples that will be translated\n",
    "    \n",
    "    The intents for the Watson Assistant are retreived in the \n",
    "    previous cell. This function takes each intent and gets the examples. \n",
    "    It transforms the list of examples into a string seperated by commas\n",
    "    \n",
    "    Args:\n",
    "    - intent: the intent to retrieve the examples for\n",
    "    \n",
    "    Returns:\n",
    "    - examples_list: string of the examples joined together with a comma\n",
    "    \n",
    "    \"\"\"\n",
    "    examples = sdk_object.list_examples(workspace_id=assistant_information['workspace_id'], \n",
    "                                        intent=intent).get_result()\n",
    "    examples = examples['examples']\n",
    "    \n",
    "    examples_list = [example['text'].replace(',', ' ') for example in examples]\n",
    "    examples_list = ','.join(examples_list)\n",
    "    \n",
    "    return examples_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_examples = [_get_intent_examples(intent) for intent in intents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_df = pd.DataFrame({\"intents\": intents, \"examples\": intents_examples})\n",
    "intent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expands the comma seperated list into individual rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(intent_df.examples.str.split(',').tolist(), \n",
    "                       index=intent_df.intents).stack()\n",
    "temp_df = temp_df.reset_index([0, 'intents'])\n",
    "temp_df.columns = ['intents', 'examples']\n",
    "intents_df = temp_df.copy()\n",
    "\n",
    "intents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate the Intent Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "intents_df['translated_examples'] = intents_df['examples'].progress_apply(lambda x: translate(x))\n",
    "\n",
    "intents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_intents = intents_df[['translated_examples', 'intents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities() -> []:\n",
    "    \"\"\" Retrieves the entities for the assistant\n",
    "    \"\"\"\n",
    "    response = sdk_object.list_entities(workspace_id=assistant_information['workspace_id'], \n",
    "                                        export=True).get_result()\n",
    "    \n",
    "    return response['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = get_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_names = [entity['entity'] for entity in entities for value in entity['values'] if value['type'] == 'synonyms'] # retrieve the entity snyonyms \n",
    "not_translated = [entity['entity'] for entity in entities for value in entity['values'] if value['type'] != 'synonyms'] # keep track of the non translated entities (these are the sys entities and contextual)\n",
    "values = [value['value'] for entity in entities for value in entity['values'] if value['type'] == 'synonyms'] # extract the value of the entities\n",
    "synonyms = [','.join(value['synonyms']) for entity in entities for value in entity['values'] if value['type'] == 'synonyms'] # join the synonyms together in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pd.DataFrame({\"entity\": entity_names, \"values\": values, \"synonyms\": synonyms})\n",
    "entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_data(file_name=\"Entities_English.csv\", data=entities_df.to_csv(header=True, index=False, encoding='utf-8'), overwrite=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_values_df = entities_df['synonyms'].str.split(',', expand=True) # tran\n",
    "entity_values_df_t = entity_values_df.T\n",
    "entity_values_translated_t = entity_values_df_t.applymap(lambda x: translate(x) if x is not None else x) # applyMap applies the translate function to every synonym in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_values_translated_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_values_translated = entity_values_translated_t.T\n",
    "entity_values_translated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_values_translated.insert(loc=0, column='entities', value=entities_df['entity'])\n",
    "entity_values_translated.insert(loc=1, column='values', value=entities_df['values'])\n",
    "entity_values_translated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_values_translated['values'] = entity_values_translated['values'].progress_apply(lambda x: translate(x)) # translate the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Dialog Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is only section that requires a manual upload of a Data Asset. \n",
    "\n",
    "1. Import the skill into the workspace by clicking on *insert credentials* -- This will auto-populate the cell below with details of your COS instance\n",
    "2. Next, navigate to your COS bucket where this Notebook is stored and retrieve the resource CRN.\n",
    "3. In the cell below, change the variable to the name of your skill. It is best to keep the same name everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKILL_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'IAM_SERVICE_ID': '',\n",
    "    'IBM_API_KEY_ID': '',\n",
    "    'ENDPOINT': '',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n",
    "    'BUCKET': '',\n",
    "    'FILE': SKILL_NAME\n",
    "}\n",
    "\n",
    "COS_RESOURCE_CRN = \"\"\n",
    "\n",
    "cos = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=credentials_1['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    ibm_auth_endpoint=credentials_1['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=credentials_1['ENDPOINT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_contents(bucket_name:str, _filter:str) -> []:\n",
    "    \"\"\"Retrieves the skill from the COS. \n",
    "    This function searches the bucket until the file name is met.\n",
    "    This function does NOT get the contents of the file, only the file path\n",
    "    \n",
    "    Args:\n",
    "    bucket_name - name of bucket where the notebook and all data assets are stored\n",
    "    _filter - name of the file\n",
    "    \"\"\"\n",
    "    print(\"Retrieving bucket contents from: {0}\".format(bucket_name))\n",
    "    try:\n",
    "        files = cos.Bucket(bucket_name).objects.all()\n",
    "        logs = [file.key for file in tqdm(files, desc=\"Retrieving Logs from COS\", \n",
    "                                          position=0, leave=True) if _filter in file.key]\n",
    "        \n",
    "        return logs\n",
    "    \n",
    "    except ClientError as be:\n",
    "        print(\"CLIENT ERROR: {0}\\n\".format(be))\n",
    "    except Exception as e:\n",
    "        print(\"Unable to retrieve bucket contents: {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_file = get_bucket_contents(\"notebookprodforaskjac-donotdelete-pr-dh0piajhgp2k3g\", SKILL_NAME)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(bucket_name, item_name):\n",
    "    \"Retrieves the contents of the file\"\n",
    "    try:\n",
    "        file = cos.Object(bucket_name, item_name).get()\n",
    "        file = file['Body'].read()\n",
    "        file = file.decode(\"utf-8\")\n",
    "        file = json.loads(file)\n",
    "        \n",
    "        return file\n",
    "    \n",
    "    except ClientError as be:\n",
    "        print(\"CLIENT ERROR: {0}\\n\".format(be))\n",
    "    except Exception as e:\n",
    "        print(\"Unable to retrieve file contents: {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_json = get_item(\"\", skill_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(obj, key):\n",
    "    \"\"\"Pull all values of specified key from nested JSON.\"\"\"\n",
    "    text_dict = dict()\n",
    "\n",
    "    def replace(obj, arr, key):\n",
    "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if k == 'options': # check for options first because we do not want to recursively translate any thing else\n",
    "                    for idx, option in enumerate(v):\n",
    "                        label = option['label']\n",
    "                        label_trans  = translate(label)\n",
    "                        option['label'] = str(label_trans)\n",
    "                        v[idx] = option\n",
    "                        obj[k] = v\n",
    "                    continue\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    replace(v, arr, key)\n",
    "                elif k == 'title':\n",
    "                    sen = translate(v)\n",
    "                    obj[k] = str(sen)\n",
    "                elif k == key:\n",
    "                    sen = translate(v)\n",
    "                    obj[k] = str(sen) # exchange/replace values. TODO: need to implement key doesn't exist case\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                replace(item, arr, key)\n",
    "        return text_dict\n",
    "\n",
    "    results = replace(obj, text_dict, key)\n",
    "    \n",
    "    return results, obj  # Obj is added to be able to see dialog_nodes JSON result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = replace_values(skill_json['dialog_nodes'], 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell saves the translated Skills, Entities, and Intents to the Data Assets folder in Watson Studio. You can ignore this cell if you are running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_data(file_name=\"Translated_Skill.json\", data=json.dumps(result, indent=2), overwrite=True);\n",
    "project.save_data(file_name=\"Translated_Entities.csv\", data=entity_values_translated.to_csv(header=False, index=False, encoding='utf-8'), overwrite=True);\n",
    "project.save_data(file_name='Translated_Intents.csv', data=translated_intents.to_csv(header=False, index=False, encoding='utf-8'), overwrite=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below, if you are running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_file = open(\"Translated_Skill.json\", \"w\") \n",
    "json.dump(result, out_file, indent = 6) \n",
    "skill_file.close() \n",
    "\n",
    "entity_values_translated.to_csv(\"Translated_Entities.csv\", header=False, index=False, encoding='utf-8')\n",
    "translated_intents.to_csv(\"Translated_Intents.csv\", header=False, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "today = dt.today().strftime(\"%y-%m-%d\")\n",
    "\n",
    "skill_file = f\"Translated_Skill_{today}.json\"\n",
    "entity_file = f\"Translated_Entities_{today}.csv\"\n",
    "intents_file = f\"Translated_Intents_{today}.csv\"\n",
    "zip_file = f\"Translated_Results_{today}.zip\"\n",
    "\n",
    "with open(skill_file, 'w') as outfile:\n",
    "    json.dump(skill_json, outfile, indent=2)\n",
    "\n",
    "entity_values_translated.to_csv(entity_file, header=False, index=False, encoding='utf-8')\n",
    "translated_intents.to_csv(intents_file, header=False, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(zip_file, 'w') as zip: \n",
    "        # writing each file one by one \n",
    "        for file in [skill_file, entity_file, intents_file]: \n",
    "            zip.write(file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below if you are running on Watson Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def copy_python_env_file_to_project_asset(project=project, python_env_source_dir='python environemnt source directory', python_env_filename='python environment file name'):\n",
    "    filename_with_path=python_env_source_dir+'/'+python_env_filename\n",
    "    print('Source directory listing: ')\n",
    "    print(os.listdir(python_env_source_dir))\n",
    "    print('File: ')\n",
    "    print(os.stat(filename_with_path))\n",
    "    print('Copying file {0} from python environment to project assets'.format(python_env_filename))\n",
    "    file_data=open(filename_with_path, 'rb')\n",
    "    project.save_data(data=file_data.read(),file_name=python_env_filename,overwrite=True)\n",
    "    file_data.close() \n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "copy_python_env_file_to_project_asset(project=project, python_env_source_dir='.', python_env_filename=zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
